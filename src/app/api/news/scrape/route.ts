/**
 * API Endpoint: POST /api/news/scrape
 *
 * Pipeline H√≠brido de Scraping:
 * - FASE 1 (Firecrawl): Descubre URLs en p√°ginas de categor√≠as
 * - FASE 2 (Crawl4AI): Extrae contenido completo de art√≠culos
 */

import { NextRequest, NextResponse } from "next/server";
import { auth } from "@/lib/auth";
import { headers } from "next/headers";
import {
  createBulletin,
  getTodayBulletin,
  updateBulletinRawNews,
  updateBulletinFullArticles,
  updateBulletinStatus,
  createBulletinLog,
  updateBulletinClassification,
} from "@/lib/db/queries/bulletins";
import { scrapeAllSources, enrichWithFullContent, type ScrapedArticle } from "@/lib/news/scraper";
import { checkCrawl4AIHealth } from "@/lib/crawl4ai";

// Timeout m√°ximo del servidor: 4 minutos (debe ser menor que el frontend de 5 min)
export const maxDuration = 240;

/**
 * Verifica si un proceso de bolet√≠n qued√≥ atascado
 * Un proceso se considera atascado si lleva m√°s de 10 minutos desde su creaci√≥n
 */
function isStaleProcess(bulletin: { createdAt: Date }): boolean {
  const STALE_THRESHOLD_MS = 10 * 60 * 1000; // 10 minutos
  const timeSinceCreation = Date.now() - new Date(bulletin.createdAt).getTime();

  if (timeSinceCreation > STALE_THRESHOLD_MS) {
    console.log(`‚ö†Ô∏è  Bolet√≠n atascado detectado (${Math.round(timeSinceCreation / 1000 / 60)} minutos desde creaci√≥n)`);
    return true;
  }

  return false;
}

/**
 * POST /api/news/scrape
 *
 * Scrapea noticias y crea bolet√≠n
 */
export async function POST(request: NextRequest) {
  const startTime = Date.now();

  try {
    // Validar autenticaci√≥n
    const session = await auth.api.getSession({
      headers: await headers(),
    });

    if (!session) {
      return NextResponse.json({ error: "No autorizado" }, { status: 401 });
    }

    console.log(`üîê Usuario autenticado: ${session.user.email}`);

    // Verificar salud de Crawl4AI antes de iniciar
    console.log("üè• Verificando conexi√≥n con Crawl4AI...");
    const isCrawl4AIHealthy = await checkCrawl4AIHealth();
    if (!isCrawl4AIHealthy) {
      console.error("‚ùå Crawl4AI no est√° disponible");
      return NextResponse.json(
        {
          error: "El servicio de scraping (Crawl4AI) no est√° disponible. Verifica que el servicio est√© corriendo.",
          details: `URL configurada: ${process.env.CRAWL4AI_API_URL || 'http://crawl4ai_api:11235'}`,
        },
        { status: 503 }
      );
    }
    console.log("‚úÖ Crawl4AI disponible");

    // Verificar si ya existe bolet√≠n de hoy
    const todayBulletin = await getTodayBulletin();

    if (todayBulletin) {
      // Verificar si el bolet√≠n est√° "realmente" en proceso o solo qued√≥ atascado
      const isStale = isStaleProcess(todayBulletin);

      // Solo permitir re-creaci√≥n si el bolet√≠n fall√≥ o qued√≥ atascado
      if (todayBulletin.status === "failed") {
        console.log(`‚ö†Ô∏è  Bolet√≠n de hoy fall√≥ (${todayBulletin.status}), se crear√° uno nuevo`);
      } else if (isStale) {
        console.log(`‚ö†Ô∏è  Bolet√≠n de hoy qued√≥ atascado (${todayBulletin.status}), se crear√° uno nuevo`);
      } else {
        // Bolet√≠n existe y est√° en proceso o completado ‚Üí bloquear
        return NextResponse.json(
          {
            error: "Ya existe un bolet√≠n para hoy",
            bulletinId: todayBulletin.id,
            status: todayBulletin.status,
          },
          { status: 409 }
        );
      }
    }

    // Crear nuevo bulletin con status 'scraping'
    const bulletin = await createBulletin({ status: "scraping" });

    console.log(`üìÑ Bolet√≠n creado: ${bulletin.id}`);

    // Crear log de inicio
    await createBulletinLog(
      bulletin.id,
      "scraping",
      "in_progress",
      "Iniciando scraping de fuentes",
      { startTime }
    );

    // Obtener configuraci√≥n del request body
    const body = await request.json().catch(() => ({}));
    const disableFirecrawl = process.env.DISABLE_FIRECRAWL === "true";
    const enableCrawl4AI = body.enableCrawl4AI ?? true; // Habilitado por defecto

    // FASE 1: Scrapear todas las fuentes
    const phase1Start = Date.now();
    if (disableFirecrawl) {
      console.log("üîç FASE 1: Iniciando scraping con Crawl4AI (Firecrawl deshabilitado)...");
    } else {
      console.log("üîç FASE 1: Iniciando scraping con Firecrawl...");
    }
    console.log(`‚è±Ô∏è  TIMESTAMP: ${new Date().toISOString()}`);

    const scrapeResult = await scrapeAllSources();

    const phase1Duration = (Date.now() - phase1Start) / 1000;
    console.log(
      `‚úÖ FASE 1 completada: ${scrapeResult.metadata.totalArticles} art√≠culos descubiertos en ${phase1Duration.toFixed(2)}s`
    );

    // Actualizar bulletin con raw news (sin metadata)
    const { metadata, ...rawNewsOnly } = scrapeResult;
    await updateBulletinRawNews(
      bulletin.id,
      rawNewsOnly,
      scrapeResult.metadata.totalArticles
    );

    // Crear log de FASE 1
    await createBulletinLog(
      bulletin.id,
      "scraping",
      "completed",
      `FASE 1 (Firecrawl) completada: ${scrapeResult.metadata.totalArticles} art√≠culos de ${scrapeResult.metadata.sourcesSuccess} fuentes`,
      {
        duration: phase1Duration * 1000, // Convertir segundos a milisegundos
        totalArticles: scrapeResult.metadata.totalArticles,
        sourcesSuccess: scrapeResult.metadata.sourcesSuccess,
        sourcesFailed: scrapeResult.metadata.sourcesFailed,
      }
    );

    // FASE 2: Enriquecer con Crawl4AI (opcional)
    // Si ya usamos Crawl4AI en FASE 1, saltamos FASE 2
    let enrichedResult = scrapeResult;
    let crawl4aiStats = null;

    if (disableFirecrawl) {
      console.log("‚è≠Ô∏è  FASE 2 omitida: Ya se us√≥ Crawl4AI en FASE 1");
      crawl4aiStats = {
        enabled: false,
        reason: "Already used in FASE 1",
      };
    } else if (enableCrawl4AI) {
      console.log("üöÄ FASE 2: Enriqueciendo con Crawl4AI...");

      try {
        const phase2Start = Date.now();

        // Crear log de inicio FASE 2
        await createBulletinLog(
          bulletin.id,
          "enrichment",
          "in_progress",
          "Iniciando enriquecimiento con Crawl4AI",
          { startTime: phase2Start }
        );

        // Enriquecer art√≠culos con contenido completo
        enrichedResult = await enrichWithFullContent(scrapeResult, {
          maxConcurrency: 5,
          enableEnrichment: true,
        });

        const phase2Duration = Date.now() - phase2Start;

        // Calcular estad√≠sticas
        const totalArticles = scrapeResult.metadata.totalArticles;
        const enrichedCount = Object.values(enrichedResult)
          .filter((value) => Array.isArray(value))
          .reduce((count: number, articles: Array<{ fullContent?: string }>) => {
            return (
              count +
              articles.filter((article) => article.fullContent).length
            );
          }, 0);

        crawl4aiStats = {
          enabled: true,
          totalArticles,
          enrichedArticles: enrichedCount,
          failedArticles: totalArticles - enrichedCount,
          successRate: ((enrichedCount / totalArticles) * 100).toFixed(2) + "%",
          duration: phase2Duration,
        };

        // Actualizar bulletin con art√≠culos completos
        const { metadata: _metadata, ...fullArticlesOnly } = enrichedResult;
        await updateBulletinFullArticles(
          bulletin.id,
          fullArticlesOnly,
          crawl4aiStats
        );

        // Crear log de FASE 2
        await createBulletinLog(
          bulletin.id,
          "enrichment",
          "completed",
          `FASE 2 (Crawl4AI) completada: ${enrichedCount}/${totalArticles} art√≠culos enriquecidos`,
          crawl4aiStats
        );

        console.log(
          `‚úÖ FASE 2 completada: ${enrichedCount}/${totalArticles} art√≠culos enriquecidos`
        );
      } catch (error) {
        console.error("‚ùå Error en FASE 2 (Crawl4AI):", error);

        // Log de error pero continuar
        await createBulletinLog(
          bulletin.id,
          "enrichment",
          "failed",
          `Error en enriquecimiento: ${(error as Error).message}`,
          { error: (error as Error).message }
        );

        // Crawl4AI fall√≥, pero tenemos los datos de Firecrawl
        crawl4aiStats = {
          enabled: true,
          failed: true,
          error: (error as Error).message,
        };
      }
    } else {
      console.log("‚è≠Ô∏è  FASE 2 (Crawl4AI) deshabilitada");
      crawl4aiStats = { enabled: false };
    }

    // CLASIFICACI√ìN AUTOM√ÅTICA: Organizar art√≠culos por categor√≠a (sin IA)
    console.log("üìÇ Iniciando clasificaci√≥n autom√°tica por URL...");
    const classificationStart = Date.now();

    const classified = {
      economia: [] as ScrapedArticle[],
      politica: [] as ScrapedArticle[],
      sociedad: [] as ScrapedArticle[],
      seguridad: [] as ScrapedArticle[],
      internacional: [] as ScrapedArticle[],
      vial: [] as ScrapedArticle[],
    };

    // Clasificar art√≠culos bas√°ndose en el campo category ya asignado
    const allArticles = [
      ...enrichedResult.primicias,
      ...enrichedResult.laHora,
      ...enrichedResult.elComercio,
      ...enrichedResult.teleamazonas,
      ...enrichedResult.ecu911,
    ];

    let classifiedCount = 0;
    let unclassifiedCount = 0;

    for (const article of allArticles) {
      if (article.category) {
        classified[article.category].push(article);
        classifiedCount++;
      } else {
        console.warn(`  ‚ö†Ô∏è  Art√≠culo sin categor√≠a: ${article.title.substring(0, 50)}...`);
        unclassifiedCount++;
      }
    }

    const classificationDuration = Date.now() - classificationStart;

    console.log(`‚úÖ Clasificaci√≥n autom√°tica completada: ${classifiedCount} art√≠culos clasificados, ${unclassifiedCount} sin clasificar`);
    console.log(`  üìä Distribuci√≥n:`);
    console.log(`     Econom√≠a: ${classified.economia.length}`);
    console.log(`     Pol√≠tica: ${classified.politica.length}`);
    console.log(`     Sociedad: ${classified.sociedad.length}`);
    console.log(`     Seguridad: ${classified.seguridad.length}`);
    console.log(`     Internacional: ${classified.internacional.length}`);
    console.log(`     Vial: ${classified.vial.length}`);

    // Guardar clasificaci√≥n en la base de datos
    await updateBulletinClassification(bulletin.id, classified);

    // Log de clasificaci√≥n
    await createBulletinLog(
      bulletin.id,
      "classification",
      "completed",
      `Clasificaci√≥n autom√°tica por URL: ${classifiedCount} art√≠culos clasificados`,
      {
        duration: classificationDuration,
        totalArticles: allArticles.length,
        classified: classifiedCount,
        unclassified: unclassifiedCount,
        distribution: {
          economia: classified.economia.length,
          politica: classified.politica.length,
          sociedad: classified.sociedad.length,
          seguridad: classified.seguridad.length,
          internacional: classified.internacional.length,
          vial: classified.vial.length,
        },
      }
    );

    // Actualizar status a 'scraped' (listo para revisi√≥n, pendiente de generar res√∫menes)
    await updateBulletinStatus(bulletin.id, "scraped");

    // Calcular duraci√≥n total
    const duration = Date.now() - startTime;

    // Preparar respuesta
    const response = {
      success: true,
      bulletinId: bulletin.id,
      totalNews: scrapeResult.metadata.totalArticles,
      sources: {
        primicias: enrichedResult.primicias.length,
        laHora: enrichedResult.laHora.length,
        elComercio: enrichedResult.elComercio.length,
        teleamazonas: enrichedResult.teleamazonas.length,
        ecu911: enrichedResult.ecu911.length,
      },
      metadata: {
        sourcesSuccess: scrapeResult.metadata.sourcesSuccess,
        sourcesFailed: scrapeResult.metadata.sourcesFailed,
        errors: scrapeResult.metadata.errors,
        duration: `${(duration / 1000).toFixed(2)}s`,
      },
      crawl4ai: crawl4aiStats,
    };

    console.log(`‚úÖ Pipeline h√≠brido completado en ${(duration / 1000).toFixed(2)}s`);

    return NextResponse.json(response);
  } catch (error) {
    console.error("‚ùå Error en scraping:", error);

    const duration = Date.now() - startTime;

    // Intentar actualizar el bulletin si se cre√≥
    try {
      const todayBulletin = await getTodayBulletin();
      if (todayBulletin && todayBulletin.status === "scraping") {
        await updateBulletinStatus(todayBulletin.id, "failed");
        await createBulletinLog(
          todayBulletin.id,
          "scraping",
          "failed",
          `Error en scraping: ${(error as Error).message}`,
          { duration, error: (error as Error).message }
        );
      }
    } catch (logError) {
      console.error("Error logging failure:", logError);
    }

    return NextResponse.json(
      {
        error: "Error scrapeando noticias",
        message: (error as Error).message,
      },
      { status: 500 }
    );
  }
}
